{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().\\\n",
    "    setAppName('sentiment-analysis').\\\n",
    "    setMaster('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, HiveContext\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlContext = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe functions\n",
    "from pyspark.sql import functions as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RDDs\n",
    "# We can create a dataframe from a RDD using the sqlContext.\n",
    "documents_rdd = sc.parallelize([\n",
    "         [1, 'cats are cute', 0],\n",
    "        [2, 'dogs are playfull', 0],\n",
    "        [3, 'lions are big', 1],\n",
    "        [4, 'cars are fast', 1]])\n",
    "users_rdd = sc.parallelize([\n",
    "        [0, 'Alice', 20],\n",
    "        [1, 'Bob', 23],\n",
    "        [2, 'Charles', 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous RDDs, we can call the toDF method and specify the name of columns:\n",
    "documents_df = documents_rdd.toDF(['doc_id', 'text', 'user_id'])\n",
    "users_df = users_rdd.toDF(['user_id', 'name', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- doc_id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark will automatically try to guess the column types. We can take a look at those types:\n",
    "documents_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to SQL, we can apply a function to a column or several columns.\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[avg(age): double]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the average age of users\n",
    "user_age_df = users_df.select(fn.avg('age'))\n",
    "user_age_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    25.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As you can see, the function is not evaluated until an action (e.g., take, show, collect) is taken\n",
    "user_age_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+------+-----------------+\n",
      "|user_id| name|age|doc_id|             text|\n",
      "+-------+-----+---+------+-----------------+\n",
      "|      0|Alice| 20|     1|    cats are cute|\n",
      "|      0|Alice| 20|     2|dogs are playfull|\n",
      "|      1|  Bob| 23|     3|    lions are big|\n",
      "|      1|  Bob| 23|     4|    cars are fast|\n",
      "+-------+-----+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can cross (e.g., join) two dataframes ala SQL.\n",
    "users_df.join(documents_df, on='user_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---+------+-----------------+\n",
      "|user_id|   name|age|doc_id|             text|\n",
      "+-------+-------+---+------+-----------------+\n",
      "|      0|  Alice| 20|     1|    cats are cute|\n",
      "|      0|  Alice| 20|     2|dogs are playfull|\n",
      "|      1|    Bob| 23|     3|    lions are big|\n",
      "|      1|    Bob| 23|     4|    cars are fast|\n",
      "|      2|Charles| 32|  null|             null|\n",
      "+-------+-------+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also do outer joins\n",
    "users_df.join(documents_df, on='user_id', how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+\n",
      "|user_id|   name|count(text)|\n",
      "+-------+-------+-----------+\n",
      "|      0|  Alice|          2|\n",
      "|      1|    Bob|          2|\n",
      "|      2|Charles|          0|\n",
      "+-------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can apply group functions.\n",
    "users_df.join(documents_df, 'user_id', how='left').\\\n",
    "    groupby('user_id', 'name').\\\n",
    "    agg(fn.count('text')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|   name|n_pets|\n",
      "+-------+-------+------+\n",
      "|      0|  Alice|     2|\n",
      "|      1|    Bob|     2|\n",
      "|      2|Charles|     0|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can change the name of computed columns:\n",
    "users_df.join(documents_df, 'user_id', how='left').\\\n",
    "    groupby('user_id', 'name').\\\n",
    "    agg(fn.count('text').alias('n_pets')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---+-----------+\n",
      "|user_id|   name|age|name_length|\n",
      "+-------+-------+---+-----------+\n",
      "|      0|  Alice| 20|          5|\n",
      "|      1|    Bob| 23|          3|\n",
      "|      2|Charles| 32|          7|\n",
      "+-------+-------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add columns:\n",
    "users_df.withColumn('name_length', fn.length('name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers and Estimators\n",
    "There are several ways of transforming the data from raw input to something that can be analyzed with a statistical model.\n",
    "\n",
    "Some examples of such transformers are displayed below:\n",
    "\n",
    "Tokenizer\n",
    "Suppose that we want to split the words or tokens of a document. This is what Tokenizer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all transfomers and estimator require you to specifiy the input column of the dataframe and the output column that will be added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tokenizer object\n",
    "tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+--------------------+\n",
      "|doc_id|             text|user_id|               words|\n",
      "+------+-----------------+-------+--------------------+\n",
      "|     1|    cats are cute|      0|   [cats, are, cute]|\n",
      "|     2|dogs are playfull|      0|[dogs, are, playf...|\n",
      "|     3|    lions are big|      1|   [lions, are, big]|\n",
      "|     4|    cars are fast|      1|   [cars, are, fast]|\n",
      "+------+-----------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can now transform the dataframe\n",
    "tokenizer.transform(documents_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer\n",
    "This transformer counts how many times a word appears in a list and produces a vector with such counts. This is very useful for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CountVectorizer is different from a Tokenizer because it needs to learn how many different tokens there are in the input column. With that number, it will output vectors with consistent dimensions. Therefore, CountVectorizer is an Estimator that, when fitted, returns a Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_estimator = CountVectorizer().setInputCol('words').setOutputCol('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to user the words column that generated by the tokenizer transformer.\n",
    "count_vectorizer_transformer = count_vectorizer_estimator.fit(tokenizer.transform(documents_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|doc_id|text             |user_id|words                |features                 |\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|1     |cats are cute    |0      |[cats, are, cute]    |(9,[0,4,7],[1.0,1.0,1.0])|\n",
      "|2     |dogs are playfull|0      |[dogs, are, playfull]|(9,[0,5,6],[1.0,1.0,1.0])|\n",
      "|3     |lions are big    |1      |[lions, are, big]    |(9,[0,1,2],[1.0,1.0,1.0])|\n",
      "|4     |cars are fast    |1      |[cars, are, fast]    |(9,[0,3,8],[1.0,1.0,1.0])|\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#which results in:\n",
    "count_vectorizer_transformer.transform(tokenizer.transform(documents_df)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column features is a sparse vector representation. For example, for the first document, we have three features present: 0, 3, and 5. By looking at the vocabulary learned by count_vectorizer_transformer, we can know which words those feature indices refer to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'big', 'lions', 'cars', 'cats', 'dogs', 'playfull', 'cute', 'fast']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of words in the vocabulary\n",
    "count_vectorizer_transformer.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['are', 'cars', 'dogs'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(count_vectorizer_transformer.vocabulary)[[0, 3, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines\n",
    "\n",
    "Sometimes, we have long preprocessing steps that take raw data and transform it through several stages. As explained before, these complex transformations can be captured by Pipelines.\n",
    "\n",
    "Pipelines are always estimators, even when they contain several transformers. After a pipeline is fit to the data, the pipeline becomes an transformer.\n",
    "\n",
    "We will now define a pipeline that takes the raw text column and produces the features column previously explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_estimator = Pipeline(stages=[tokenizer, count_vectorizer_estimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_transformer = pipeline_cv_estimator.fit(documents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+--------------------+--------------------+\n",
      "|doc_id|             text|user_id|               words|            features|\n",
      "+------+-----------------+-------+--------------------+--------------------+\n",
      "|     1|    cats are cute|      0|   [cats, are, cute]|(9,[0,4,8],[1.0,1...|\n",
      "|     2|dogs are playfull|      0|[dogs, are, playf...|(9,[0,2,7],[1.0,1...|\n",
      "|     3|    lions are big|      1|   [lions, are, big]|(9,[0,1,3],[1.0,1...|\n",
      "|     4|    cars are fast|      1|   [cars, are, fast]|(9,[0,5,6],[1.0,1...|\n",
      "+------+-----------------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_cv_transformer.transform(documents_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more complex scenarios, you can even chain Pipeline transformers. We will see this case in the actual use case below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the review, sentiment, and tweet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = sqlContext.read.parquet('sentiments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- sentiment: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema is very simple: for each word, we have whether it is positive (+1) or negative (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|         word|sentiment|\n",
      "+-------------+---------+\n",
      "|   gratefully|        1|\n",
      "|gratification|        1|\n",
      "|    gratified|        1|\n",
      "|    gratifies|        1|\n",
      "|      gratify|        1|\n",
      "+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a sample of positive words\n",
    "sentiments_df.where(fn.col('sentiment') == 1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|      word|sentiment|\n",
      "+----------+---------+\n",
      "|   2-faced|       -1|\n",
      "|   2-faces|       -1|\n",
      "|  abnormal|       -1|\n",
      "|   abolish|       -1|\n",
      "|abominable|       -1|\n",
      "+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a sample of negative words\n",
    "sentiments_df.where(fn.col('sentiment') == -1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|sentiment|count(1)|\n",
      "+---------+--------+\n",
      "|        1|    2006|\n",
      "|       -1|    4783|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many of each category we have\n",
    "sentiments_df.groupBy('sentiment').agg(fn.count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have almost two times the number of negative words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple approach to sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple approach for sentiment analysis is to simple count the number of positive and negative words in a text and then compute the average sentiment. Assuming that positive words are +1 and negative words are -1, we can classify a text as positive if the average sentiment is greater than zero and negative otherwise\n",
    "\n",
    "To test our approach, we will use a sample of IMDB reviews that were tagged as positive and negative.\n",
    "\n",
    "Let’s load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_df = sqlContext.read.parquet('imdb_reviews_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='pos_10006', review='In this \"critically acclaimed psychological thriller based on true events, Gabriel (Robin Williams), a celebrated writer and late-night talk show host, becomes captivated by the harrowing story of a young listener and his adoptive mother (Toni Collette). When troubling questions arise about this boy\\'s (story), however, Gabriel finds himself drawn into a widening mystery that hides a deadly secret\\x85\" according to film\\'s official synopsis.<br /><br />You really should STOP reading these comments, and watch the film NOW...<br /><br />The \"How did he lose his leg?\" ending, with Ms. Collette planning her new life, should be chopped off, and sent to \"deleted scenes\" land. It\\'s overkill. The true nature of her physical and mental ailments should be obvious, by the time Mr. Williams returns to New York. Possibly, her blindness could be in question - but a revelation could have be made certain in either the \"highway\" or \"video tape\" scenes. The film would benefit from a re-editing - how about a \"director\\'s cut\"? <br /><br />Williams and Bobby Cannavale (as Jess) don\\'t seem, initially, believable as a couple. A scene or two establishing their relationship might have helped set the stage. Otherwise, the cast is exemplary. Williams offers an exceptionally strong characterization, and not a \"gay impersonation\". Sandra Oh (as Anna), Joe Morton (as Ashe), and Rory Culkin (Pete Logand) are all perfect.<br /><br />Best of all, Collette\\'s \"Donna\" belongs in the creepy hall of fame. Ms. Oh is correct in saying Collette might be, \"you know, like that guy from \\'Psycho\\'.\" There have been several years when organizations giving acting awards seemed to reach for women, due to a slighter dispersion of roles; certainly, they could have noticed Collette with some award consideration. She is that good. And, director Patrick Stettner definitely evokes Hitchcock - he even makes getting a sandwich from a vending machine suspenseful.<br /><br />Finally, writers Stettner, Armistead Maupin, and Terry Anderson deserve gratitude from flight attendants everywhere.<br /><br />******* The Night Listener (1/21/06) Patrick Stettner ~ Robin Williams, Toni Collette, Sandra Oh, Rory Culkin', score=1.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_df.where(fn.col('score') == 1).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='neg_10006', review=\"I don't know who to blame, the timid writers or the clueless director. It seemed to be one of those movies where so much was paid to the stars (Angie, Charlie, Denise, Rosanna and Jon) that there wasn't enough left to really make a movie. This could have been very entertaining, but there was a veil of timidity, even cowardice, that hung over each scene. Since it got an R rating anyway why was the ubiquitous bubble bath scene shot with a 70-year-old woman and not Angie Harmon? Why does Sheen sleepwalk through potentially hot relationships WITH TWO OF THE MOST BEAUTIFUL AND SEXY ACTRESSES in the world? If they were only looking for laughs why not cast Whoopi Goldberg and Judy Tenuta instead? This was so predictable I was surprised to find that the director wasn't a five year old. What a waste, not just for the viewers but for the actors as well.\", score=0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a negative one:\n",
    "imdb_reviews_df.where(fn.col('score') == 0).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem that we encounter is that the reviews are in plain text. We need to split the words and then match them to sentiment_df.\n",
    "\n",
    "To do, we will use a transformation that takes raw text and outputs a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegexTokenizer extracts a sequence of matches from the input text. Regular expressions are a powerful tool to extract strings with certain characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"review\")\\\n",
    "  .setOutputCol(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern \\p{L}+ means that it will extract letters without accents (e.g., it will extract “Acuna” from “Acuña”). setGaps means that it will keep applying the rule until it can’t extract new words. You have to set the input column from the incoming dataframe (in our case the review column) and the new column that will be added (e.g., words).\n",
    "\n",
    "We are ready to transform the input dataframe imdb_reviews_df with the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, review: string, score: double, words: array<string>]\n"
     ]
    }
   ],
   "source": [
    "review_words_df = tokenizer.transform(imdb_reviews_df)\n",
    "print(review_words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the transformation doesn’t actually do anything until you apply an action. But as you can see, a new column words of type array of string was added by the transformation. We can see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+--------------------+\n",
      "|       id|              review|score|               words|\n",
      "+---------+--------------------+-----+--------------------+\n",
      "|pos_10006|In this \"critical...|  1.0|[in, this, critic...|\n",
      "|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|\n",
      "|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|\n",
      "|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|\n",
      "| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|\n",
      "+---------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to match every word from sentiment_df in the array words shown before. One way of doing this is to explode the column words to create a row for each element in that list. Then, we would join that result with the dataframe sentiment to continue further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|       id|         word|\n",
      "+---------+-------------+\n",
      "|pos_10006|           in|\n",
      "|pos_10006|         this|\n",
      "|pos_10006|   critically|\n",
      "|pos_10006|    acclaimed|\n",
      "|pos_10006|psychological|\n",
      "+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_words_df.select('id', fn.explode('words').alias('word')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we join that with sentiment, we can see if there are positive and negative words in each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+\n",
      "|      word|       id|sentiment|\n",
      "+----------+---------+---------+\n",
      "| acclaimed|pos_10006|        1|\n",
      "|celebrated|pos_10006|        1|\n",
      "| troubling|pos_10006|       -1|\n",
      "|   mystery|pos_10006|       -1|\n",
      "|    deadly|pos_10006|       -1|\n",
      "+----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_word_sentiment_df = review_words_df.\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    join(sentiments_df, 'word')\n",
    "review_word_sentiment_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply average the sentiment per review id and, say, pick positive when the average is above 0, and negative otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+\n",
      "|       id|       avg_sentiment|predicted|\n",
      "+---------+--------------------+---------+\n",
      "|pos_10149| 0.42857142857142855|      1.0|\n",
      "|pos_10377|  0.5384615384615384|      1.0|\n",
      "| pos_1299| 0.09090909090909091|      1.0|\n",
      "| pos_2228|-0.14285714285714285|      0.0|\n",
      "| pos_5052|  0.7777777777777778|      1.0|\n",
      "+---------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_sentiment_prediction_df = review_word_sentiment_df.\\\n",
    "    groupBy('id').\\\n",
    "    agg(fn.avg('sentiment').alias('avg_sentiment')).\\\n",
    "    withColumn('predicted', fn.when(fn.col('avg_sentiment') > 0, 1.0).otherwise(0.))\n",
    "simple_sentiment_prediction_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(correct)|\n",
      "+-----------------+\n",
      "|0.732231471106131|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now, lets compute the accuracy of our prediction\n",
    "\n",
    "imdb_reviews_df.\\\n",
    "    join(simple_sentiment_prediction_df, 'id').\\\n",
    "    select(fn.expr('float(score = predicted)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not bad with such a simple approach! But can we do better than this?                                            A data-driven sentiment prediction\n",
    "\n",
    "There are couple of problems with the previous approach: 1. Positive and negative words had the same weight (e.g., good == amazing) 1. Maybe a couple of negative words make the entire review negative, whereas positive words do not 1. While our dataset is artificially balanced (12500 positive and 12500 negative), there are usually more positive than negative reviews, and therefore we should bias our predictions towards positive ones.\n",
    "\n",
    "We could use data to estimate the sentiment that each word is contributing to the final sentiment of a review. Given that we are trying to predict negative and positve reviews, then we can use logistic regression for such binary prediction.\n",
    "\n",
    "From text to numerical features\n",
    "One typical approach is to count how many times a word appears in the text and then perform a reweighting so that words that are very common are “counted” less.\n",
    "\n",
    "In Spark, we can achieve this by using several transformers:\n",
    "\n",
    "Raw text => Tokens => Remove stop words => Term Frequency => Reweighting by Inverse Document frequency\n",
    "\n",
    "To perform this sequence we will create a Pipeline to consistently represent the steps from raw text to TF-IDF.\n",
    "\n",
    "First, we need to create a sequence to take from raw text to term frequency. This is necessary because we don’t know the number of tokens in the text and therefore we need to estimate such quantity from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we obtain the stop words from a website\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for this initial Pipeline, we define a counter vectorizer estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now create a pipelined transformer\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(imdb_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|       id|              review|score|               words|            filtered|                  tf|\n",
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|pos_10006|In this \"critical...|  1.0|[in, this, critic...|[critically, accl...|(26677,[0,1,3,4,5...|\n",
      "|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|[like, previous, ...|(26677,[1,2,3,4,5...|\n",
      "|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|[aro, tolbukhin, ...|(26677,[0,1,2,12,...|\n",
      "|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|[movie, titanic, ...|(26677,[0,1,2,3,4...|\n",
      "| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|[aussie, masterpi...|(26677,[4,5,9,24,...|\n",
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we can make the transformation between the raw text and the counts\n",
    "cv_pipeline.transform(imdb_reviews_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequency vector is represented with a sparse vector. We have 26,384 terms.\n",
    "\n",
    "Finally, we build another pipeline that takes the output of the previous pipeline and lowers the terms of documents that are very common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(imdb_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|       id|              review|score|               words|            filtered|                  tf|               tfidf|\n",
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|pos_10006|In this \"critical...|  1.0|[in, this, critic...|[critically, accl...|(26677,[0,1,3,4,5...|(26677,[0,1,3,4,5...|\n",
      "|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|[like, previous, ...|(26677,[1,2,3,4,5...|(26677,[1,2,3,4,5...|\n",
      "|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|[aro, tolbukhin, ...|(26677,[0,1,2,12,...|(26677,[0,1,2,12,...|\n",
      "|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|[movie, titanic, ...|(26677,[0,1,2,3,4...|(26677,[0,1,2,3,4...|\n",
      "| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|[aussie, masterpi...|(26677,[4,5,9,24,...|(26677,[4,5,9,24,...|\n",
      "+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf_pipeline.transform(imdb_reviews_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the idf_pipeline takes the raw text from the datafarme imdb_reviews_df and creates a feature vector vector called tfidf!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = idf_pipeline.transform(imdb_reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science pipeline for estimating sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let’s split the data into training, validation, and testing.\n",
    "training_df, validation_df, testing_df = imdb_reviews_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15081, 7350, 2569]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[training_df.count(), validation_df.count(), testing_df.count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediately apparent problem is that the number of features in the dataset is far larger than the number of training examples. This can lead to serious overfitting.\n",
    "\n",
    "Let’s look at this more closely. Let’s apply a simple prediction model known as logistic regression.\n",
    "\n",
    "Logistic regression will take the tfidf features and predict whether the review is positive (score == 1) or negative (score == 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('score').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a pipeline transformation by chaining the idf_pipeline with the logistic regression step (lr)\n",
    "lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.8440816326530612|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets estimate the accuracy:\n",
    "lr_pipeline.transform(validation_df).\\\n",
    "    select(fn.expr('float(prediction = score)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is much better than before.\n",
    "\n",
    "The problem however is that we are overfitting because we have many features compared to the training examples:\n",
    "\n",
    "For example, if we look at the weights of the features, there is a lot of noise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>albright</td>\n",
       "      <td>-6.010620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26664</th>\n",
       "      <td>dawning</td>\n",
       "      <td>-5.771948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>rallying</td>\n",
       "      <td>-3.854359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23854</th>\n",
       "      <td>disrobe</td>\n",
       "      <td>-3.828086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26053</th>\n",
       "      <td>prolong</td>\n",
       "      <td>-3.757287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word    weight\n",
       "23995  albright -6.010620\n",
       "26664   dawning -5.771948\n",
       "25217  rallying -3.854359\n",
       "23854   disrobe -3.828086\n",
       "26053   prolong -3.757287"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The most negative words are:\n",
    "coeffs_df.sort_values('weight').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>ingeniously</td>\n",
       "      <td>5.123669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22368</th>\n",
       "      <td>riffing</td>\n",
       "      <td>5.097224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25118</th>\n",
       "      <td>tweed</td>\n",
       "      <td>3.903306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>outlined</td>\n",
       "      <td>3.814566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24466</th>\n",
       "      <td>beastiality</td>\n",
       "      <td>3.813886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    weight\n",
       "20635  ingeniously  5.123669\n",
       "22368      riffing  5.097224\n",
       "25118        tweed  3.903306\n",
       "22010     outlined  3.814566\n",
       "24466  beastiality  3.813886"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And the most positive:\n",
    "coeffs_df.sort_values('weight', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But none of them make sense. What is happening? We are overfitting the data. Those words that don’t make sense are capturing just noise in the reviews.\n",
    "\n",
    "For example, the word \"helming\" appears in only one review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='pos_2548', word='helming', review='Karloff and Lugosi - Together again! This is one of those films that casual fans will pass over and tend not to appreciate as much. It\\'s not an all-out horror film like the duo\\'s previous two hits, The Black Cat and The Raven. But, it is very worthy of both\\'s talents and is a fun film when re-visited.<br /><br />The Invisible Ray was directed by Lambert Hillyer, a director who mainly made westerns, but curiously in these final days of the Laemmles\\' reign at Universal, he found himself helming this and the Laemmles\\' final horror film, Dracula\\'s Daughter. Both are crisp, clean-cut fantasies that are very light on horror content despite the fantastic elements.<br /><br />Just as Lugosi went wild in The Raven, much needs to be said of Karloff\\'s hamming in The Invisible Ray. The one aspect of the story that is particularly unsatisfying is that Karloff\\'s character, Rukh, acts so madly before he is poisoned by Radium X, that there really isn\\'t much of a change once he starts glowing. This is very similar to the complaint people have about Jack Nicholson in The Shining - He\\'s basically a loony right from the start. There isn\\'t any real transformation. Same here. Halfway through Karloff simply has an added purpose for revenge in his mind. I still enjoyed his performance, though, just as I did Lugosi\\'s over-the-top antics in The Raven.<br /><br />Meanwhile, Lugosi completely surprises you and gives a restrained, and thoughtful turn as Rukh\\'s rival in science, Dr. Benet. Lugosi also has some of the best lines in the film, including a memorable warning to the police trying to catch Rukh, of which I am in alignment with horror film writer John Soister on - \"And if he (Rukh) touches anyone?\" the inspector inquires. Lugosi hesitatingly replies, in a way that only Lugosi could deliver, \"They die\". Just as Lugosi could be so off, he could also be more perfect than any actor. This is one of those moments.<br /><br />Therefore, Karloff and Lugosi\\'s interactions are all very good as we get the mad antics of Karloff pared off against the cool logic of Lugosi. Karloff would go on to play similar mad scientists many times, however, one wishes Lugosi would have gotten to play more straight roles like this one. He only had one more chance (Ninotchka).<br /><br />The Invisible Ray is a fun film, and a real treat to the true Karloff and Lugosi fans. It is one of those films that improves on each viewing, not because it is a masterpiece, but because of the charisma and talent of its\\' stars and how this story complements the darker, more horrific pairings they had. The special effects, by the always innovative John Fulton, are terrific and the supporting actors are all adequate. Frances Drake looks as beautiful as she did in Mad Love and plays a strong woman, something seldom seen in classic horror films. The scene in the end when Karloff stalks her and she doesn\\'t scream is one of the most haunting moments of the film. A terrific, fun film!', score=1.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_pipeline.transform(training_df).\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    where(fn.col('word') == 'helming').\\\n",
    "    join(training_df, 'id').\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to prevent overfitting during training is to modify the loss function and penalize weight values that are too large.\n",
    "\n",
    "There are two major regularization techniques, one based on penalizing the squared value of the weight (called L2 or ridge regularization) and anotherbased on penalizing the absolute value of the weight (called L1 or lasso regularization).\n",
    "\n",
    "The unregularized logistic regression loss function is:\n",
    "\n",
    "Lθ(p(X),Y)=−(∑iYipθ(Xi)+(1−Yi)(1−pθ(Xi)))\n",
    "where $p_\\theta(\\cdot)$ is the sigmoid function:\n",
    "\n",
    "pθ(X)=11+exp(−(θ0+∑j>0xjθj))\n",
    "If we modify the loss function $L_\\theta$ slightly\n",
    "\n",
    "Lλθ(p(X),Y)=−(∑iYipθ(Xi)+(1−Yi)(1−pθ(Xi)))+λ∑j>0θ2j\n",
    "we obtain what is known as L2 regularization.\n",
    "\n",
    "Notice how we increase the loss function by $\\lambda$ times the square of the weights. In practice, this means that we will think twice about increasing the importance of a feature. This loss function will prevent the algorithm for fitting certain data points, such as outliers or noise, unless the decrease in loss for the data grants it. Also, notice that the penalization doesn’t apply to the bias parameter $\\theta_0$.\n",
    "\n",
    "You can see more clearly the effect of such cost function when $\\lambda$ goes to infinity: the features will not be used for predicting and only the bias term will matter! This prevents the algorithm from learning altogether, forcing it to underfit!\n",
    "\n",
    "One problem with L2 regularization is that all weights go to zero uniformly. In a sense, all features will matter but less than with the unregularized loss function. This is a really strange because we do not want all features to matter. In sentiment analysis, we want to select certain features because we want to understand that only some words have effects on the sentiment.\n",
    "\n",
    "A different modification of the original loss function can achieve this. This regularization is known as L1 or lasso reguarlization and penalizes the absolute value of the weight\n",
    "\n",
    "Lλθ(p(X),Y)=−(∑iYipθ(Xi)+(1−Yi)(1−pθ(Xi)))+λ∑j>0∣∣θj∣∣\n",
    "The practical effect of L1 regularization is that the difference between a feature having no importance vs some small importance is massively bigger than with L2 regularization. Therefore, optimizing the L1 loss function usually brings some features to have exactly zero weight.\n",
    "\n",
    "One problem with L1 regularization is that it will never select more features that the number of examples. This is because it can always fit the training data perfectly when the number of features equals the number of examples. In our sentimental analysis, this is the case (there are more words than examples).\n",
    "\n",
    "One way of remedying this is to have a combination of both L1 and L2. This is known as elastic net regularization. For this type of regularization, we have to pick a parameter ($\\alpha$) deciding to consider L1 vs L2 regularization. If $\\alpha=0$, then we choose L2, and if $\\alpha=1$ we choose L1. For example, $\\alpha=0.5$ means half L1 and half L2.\n",
    "\n",
    "Lλ,αθ(p(X),Y)=−(∑iYipθ(Xi)+(1−Yi)(1−pθ(Xi)))+λ[(1−α)∑j>0θ2j+α∑j>0∣∣θj∣∣]\n",
    "Unfortunately, elastic net regularization comes with two additional parameters, $\\lambda$ and $\\alpha$, and we must either select them a priori or used the validation set to choose the best one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark allows to fit elatic net regularization easily\n",
    "lambda_par = 0.02\n",
    "alpha_par = 0.3\n",
    "en_lr = LogisticRegression().\\\n",
    "        setLabelCol('score').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we define a new Pipeline\n",
    "en_lr_pipeline = Pipeline(stages=[idf_pipeline, en_lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|avg(float((prediction = score)))|\n",
      "+--------------------------------+\n",
      "|              0.8761904761904762|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let’s look at the performance\n",
    "en_lr_pipeline.transform(validation_df).select(fn.avg(fn.expr('float(prediction = score)'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improve performance slightly, but whats more important is that we improve the understanding of the word sentiments. Lets take at the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_weights = en_lr_pipeline.stages[-1].coefficients.toArray()\n",
    "en_coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': en_weights})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most negative words all make sense (“worst” is actually more negative than than “worse”)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.385505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.376117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.244323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.235669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>-0.209448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>fails</td>\n",
       "      <td>-0.195139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>boring</td>\n",
       "      <td>-0.190572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.185320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.177938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>mess</td>\n",
       "      <td>-0.176395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>worse</td>\n",
       "      <td>-0.175464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-0.167219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.161064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>remotely</td>\n",
       "      <td>-0.157787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.152549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word    weight\n",
       "103            worst -0.385505\n",
       "258            waste -0.376117\n",
       "201            awful -0.244323\n",
       "11               bad -0.235669\n",
       "1134  disappointment -0.209448\n",
       "754            fails -0.195139\n",
       "190           boring -0.190572\n",
       "627           poorly -0.185320\n",
       "174             poor -0.177938\n",
       "701             mess -0.176395\n",
       "254            worse -0.175464\n",
       "899        pointless -0.167219\n",
       "332         horrible -0.161064\n",
       "2318        remotely -0.157787\n",
       "569            avoid -0.152549"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.sort_values('weight').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>great</td>\n",
       "      <td>0.270940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.260410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.181065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>refreshing</td>\n",
       "      <td>0.175973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>best</td>\n",
       "      <td>0.174953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>favorite</td>\n",
       "      <td>0.159823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12415</th>\n",
       "      <td>batista</td>\n",
       "      <td>0.145553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>wonderfully</td>\n",
       "      <td>0.143651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23139</th>\n",
       "      <td>insides</td>\n",
       "      <td>0.136986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>amazing</td>\n",
       "      <td>0.133872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>today</td>\n",
       "      <td>0.133584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.133536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>0.130813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.130181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>captures</td>\n",
       "      <td>0.129534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    weight\n",
       "13           great  0.270940\n",
       "160      excellent  0.260410\n",
       "216      wonderful  0.181065\n",
       "2146    refreshing  0.175973\n",
       "29            best  0.174953\n",
       "320       favorite  0.159823\n",
       "12415      batista  0.145553\n",
       "1405   wonderfully  0.143651\n",
       "23139      insides  0.136986\n",
       "291        amazing  0.133872\n",
       "318          today  0.133584\n",
       "227        perfect  0.133536\n",
       "317        enjoyed  0.130813\n",
       "517      enjoyable  0.130181\n",
       "2056      captures  0.129534"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same thing with positive words\n",
    "en_coeffs_df.sort_values('weight', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25573, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Are there words with literarily zero importance for predicting sentiment? Yes, and most of them!\n",
    "en_coeffs_df.query('weight == 0.0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586160362859392"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In fact, more than 95% of features are not needed to achieve a better performance than all previous models!\n",
    "en_coeffs_df.query('weight == 0.0').shape[0]/en_coeffs_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>people</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>don</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>way</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>characters</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>character</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>watch</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>films</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>little</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>know</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  weight\n",
       "0           br     0.0\n",
       "3         film     0.0\n",
       "5         like     0.0\n",
       "9        story     0.0\n",
       "10      really     0.0\n",
       "12      people     0.0\n",
       "14         don     0.0\n",
       "15         way     0.0\n",
       "17      movies     0.0\n",
       "19  characters     0.0\n",
       "20   character     0.0\n",
       "21       watch     0.0\n",
       "22       films     0.0\n",
       "28      little     0.0\n",
       "31        know     0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s look at these neutral words\n",
    "en_coeffs_df.query('weight == 0.0').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, did we choose the right $\\lambda$ and $\\alpha$ parameters? We should run an experiment where we try different combinations of them. Fortunately, Spark let us do this by using a grid - a method that generates combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to build a new estimator pipeline\n",
    "en_lr_estimator = Pipeline(stages=[idf_pipeline, en_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder().\\\n",
    "    addGrid(en_lr.regParam, [0., 0.01, 0.02]).\\\n",
    "    addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the list of parameters that we will try:\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "for j in range(len(grid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = en_lr_estimator.fit(training_df, grid[j])\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the accuracy of each of them:\n",
    "accuracies = [m.\\\n",
    "    transform(validation_df).\\\n",
    "    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_idx = np.argmax(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_3c44d7b3cfc4', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       " Param(parent='LogisticRegression_3c44d7b3cfc4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So the best model we found has the following parameters\n",
    "\n",
    "grid[best_model_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_models[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844897959183673"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies[best_model_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, predicting tweet sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|text                                                                                                                                        |handle         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|RT @ZekeJMiller: Trump Tax Records Obtained by The Times Reveal He Could Have Avoided Paying Taxes for Nearly Two Decades https://t.co/2Pt8…|@HillaryClinton|\n",
      "|“She’s just out there every day doing God’s work in her own way. You know? Making her parents proud.” —Betsy, Hilla… https://t.co/ZB3Vxskqoh|@HillaryClinton|\n",
      "|We're going to make college debt-free for everyone in America. See how much you could save with Hillary's plan at… https://t.co/Fhzkubhpj7  |@HillaryClinton|\n",
      "|Don't boo. Vote! https://t.co/tTgeqy51PU https://t.co/9un3FUVxoG                                                                            |@HillaryClinton|\n",
      "|This Republican dad is struggling with the idea of his daughter growing up in a country led by Donald Trump. https://t.co/Tn3rQqJJKp        |@HillaryClinton|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we can use this model to predict sentiments on Twitter\n",
    "tweets_df = sqlContext.read.parquet('tweets.parquet')\n",
    "tweets_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|          handle|count(1)|\n",
      "+----------------+--------+\n",
      "| @HillaryClinton|    1000|\n",
      "|@realDonaldTrump|    1000|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We have 1K tweets from each candidate\n",
    "tweets_df.groupby('handle').agg(fn.count('*')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the sentiment of the Tweet using our best model, we need to rename the column so that it matches our previous pipeline (review => …)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|              review|prediction|\n",
      "+--------------------+----------+\n",
      "|RT @ZekeJMiller: ...|       1.0|\n",
      "|“She’s just out t...|       1.0|\n",
      "|We're going to ma...|       0.0|\n",
      "|Don't boo. Vote! ...|       0.0|\n",
      "|This Republican d...|       0.0|\n",
      "|Hillary teamed up...|       0.0|\n",
      "|RT @mayaharris_: ...|       1.0|\n",
      "|\"It was overwhelm...|       1.0|\n",
      "|Great step forwar...|       1.0|\n",
      "|\"I feel like I'm ...|       1.0|\n",
      "|Nobody here was “...|       1.0|\n",
      "|For those few peo...|       1.0|\n",
      "|Remember, don't b...|       1.0|\n",
      "|Too many talented...|       1.0|\n",
      "|There are hundred...|       0.0|\n",
      "|It's 3:20am. As g...|       1.0|\n",
      "|Trump stood on a ...|       1.0|\n",
      "|Donald Trump said...|       1.0|\n",
      "|RT @timkaine: 39 ...|       1.0|\n",
      "|Trump wants to br...|       1.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.transform(tweets_df.withColumnRenamed('text', 'review')).select('review', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets summarize our results in a graph!\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pd = best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    groupby('handle').\\\n",
    "    agg(fn.avg('prediction').alias('prediction'), \n",
    "        (2*fn.stddev('prediction')/fn.sqrt(fn.count('*'))).alias('err')).\\\n",
    "    toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>prediction</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@HillaryClinton</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.027721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.026506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             handle  prediction       err\n",
       "0   @HillaryClinton       0.741  0.027721\n",
       "1  @realDonaldTrump       0.773  0.026506"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAD4CAYAAAC34gzsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXZUlEQVR4nO3de5RcZZ3u8e9vSCRAEqJBNDEwHTFCIIQQAqKQOcQLg4ByVa6OASEYQHR5WAfWEY6ckbMMXjggghoYQT3hIiCIg6LiJCMBgpOEEC7hTqMBdAAHJIR7fueP2g1N0yTVebuqq8L3s1avVO391t5P707y9Lv37urITCRJ0tr7u4EOIElSu7NMJUkqZJlKklTIMpUkqZBlKklSoUEDHUDNt8kmm2RHR8dAx5CktrJo0aInMvOdva2zTN+COjo6WLhw4UDHkKS2EhEPv9k6T/NKklTIMpUkqZBlKklSIa+ZSlIbe+mll1i+fDnPP//8QEdZZwwZMoQxY8YwePDgul9jmUpSG1u+fDnDhg2jo6ODiBjoOG0vM3nyySdZvnw5Y8eOrft1nuaVpDb2/PPPM3LkSIu0n0QEI0eO7PNM3zKVpDZnkfavtTmelqkkSYW8ZipJ65COk6/t1+11ztqrX7dXj6FDh7JixQoeffRRTjjhBK644oo3HXvWWWcxY8YMNtxwQwD23HNPLr74YkaMGNGsuIAzU0lSE7zyyit9fs3o0aNXW6RQK9OVK1e++vyXv/xl04sULFNJUqHOzk622morDjvsMMaPH8+BBx7IypUr6ejo4KSTTmLy5MlcfvnlPPDAA+yxxx7ssMMOTJ06lbvvvhuAhx56iA9+8INsu+22nHLKKa/b7oQJE4BaGZ944olMmDCBiRMncs455/Cd73yHRx99lGnTpjFt2jSg9napTzzxBABnnnkmEyZMYMKECZx11lmvbnP8+PEcffTRbLPNNuy+++4899xzxcfAMpUkFbvnnns49thjWbZsGcOHD+e8884DYOTIkSxevJiDDz6YGTNmcM4557Bo0SK+9a1vceyxxwLwxS9+kZkzZ3L77bczatSoXrc/e/ZsOjs7WbJkCUuXLuWwww7jhBNOYPTo0cydO5e5c+e+bvyiRYu48MILueWWW1iwYAHnn38+t956KwD33Xcfxx13HHfeeScjRozgyiuvLP78LVNJUrHNNtuMXXbZBYDDDz+c+fPnA3DQQQcBsGLFCm666SY+9alPMWnSJI455hgee+wxAG688UYOOeQQAD7zmc/0uv3rr7+eY445hkGDarf6vOMd71htnvnz57Pffvux0UYbMXToUPbff39uuOEGAMaOHcukSZMA2GGHHejs7Cz4zGu8AUmSVKznj5N0Pd9oo40AWLVqFSNGjGDJkiV1vb6R1l9//Vcfr7feep7mlSS1hj/+8Y/cfPPNAFx88cXsuuuur1s/fPhwxo4dy+WXXw7U3mnotttuA2CXXXbh0ksvBWDOnDm9bv9jH/sYP/jBD3j55ZcB+Otf/wrAsGHDeOaZZ94wfurUqVx99dWsXLmSZ599lquuuoqpU6f2w2faO2emkrQOGYgfZQHYcsstOffccznyyCPZeuutmTlzJuecc87rxsyZM4eZM2dy+umn89JLL3HwwQez3XbbcfbZZ3PooYdyxhlnsM8++/S6/aOOOop7772XiRMnMnjwYI4++miOP/54ZsyYwR577PHqtdMukydPZvr06ey0006vvn777bfvl1O6vYnMbMiG1bqmTJmS/nJwad2wbNkyxo8fP6AZOjs72XvvvbnjjjsGNEd/6u24RsSizJzS23hP80qSVMgylSQV6ejoWKdmpWvDMpWkNufluv61NsfTMpWkNjZkyBCefPJJC7WfdP0+0yFDhvTpdd7NK0ltbMyYMSxfvpzHH398oKOsM4YMGcKYMWP69BrLVJLa2ODBgxk7duxAx3jL8zSvJEmFLFNJkgpZppIkFfKa6VvQ7Y88TcfJ1w50DEnqFwP1FordOTOVJKmQZSpJUiHLVJKkQpapJEmFLFNJkgpZppIkFbJMJUkqZJlKklTIMpUkqZBlKklSIctUkqRClqkkSYUsU0mSClmmkiQVskwlSSpkmUqSVMgylSSpkGUqSVIhy1SSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKtTwMo2Id0XE2RGxNCIWR8QFEbFZP27/oog4sHo8LyLuqfZ1d0R8NyJG9Ne+uu3ztIg4sZflHRFxR0T8Y0QsqT5WVJmWRMSP+zuLJGngNbRMI2IL4DrgRmBKZk4GLgGuqtZ1HxsR0R95DsvMicBE4AXg5/2wzT7JzF9n5qTMnAQsrDJNysx/6j4uIgY1O5skqf81+j/z7wGfzcylXQsy83cRcTjw7Yj4EvBr4BZgB2DPiNgS+N/A+sADwBGZuSIi/hfwCWAD4CbgmMzMN9txZr4YEf8DuD8itsvM2yLiy8CR1ZALMvOsiOgAfgXMBz4EPALsk5nPRcTRwAzgbcD9wGcyc2X3/UTEDsAPq6e/WdMBiYijgL2BjYFVEfF14PjM3Lda/31gfmb+v4hYDvwY2At4ETgGmAVsAczKzPMj4qPAV4DngfcC11fbe9NjI0mt7s8Xn1z32N0WfLOucfPmzVvLNGvWsJlpRLwfeDwzl0bE3tUp3isi4srMvBtYBWwCjAPOy8xtgGeBU4CPVrPYhcCXq01+NzN3zMwJ1Ap17zVlyMxXgNuArarSOwL4ALAzcHREbF8NHQecW2V4CjigWv6zap/bAcuAz/WymwuBL1Rj6rU9sH9mfqSOsQ9V214A/AuwH7XS/1q3MR8AZgJbA+OBfXpuJCJmRMTCiFj4ysqn+xBVkrQmjZyZbgcsiIj1gK8CH6Y2G7ujWn8fEMDDmbmgWrYztUK4MSKgNiO8uVo3rZppbgi8A7gT+EUdOaL6c1fgqsx8FiAifgZMBa6hVlhLqnGLgI7q8YSIOB0YAQylNot+bcO167EjMvP31aKfAB+vI9NvMvO/6hhHlQ/gdmBQlf/ZiFgVEUOrdQsys7PKdGn1uV7dfSOZORuYDbD+qHHOWiW1tHcfOqvusfNm7dXAJPVp9GneV6jNPh/IzKeApyLirmrdptSK8dlu4wP4bWYe0n0jETEEOI/addc/RcRpwJA17bwq8m2pzSrfvZqhL/TIvEH1+CJg3+oU8XRgtzXts07dP+eXef0Zgp6fV1e2VT1yruK1r1/PcrQsJamJGnkD0h3UTj8+AWwRERtHxObA+IjYllqZPtzjNQuAXSLifQARsVF1urirYJ6oZmMHrmnnETEY+Drwp+qa7Q3AvhGxYURsRO106Q1r2Mww4LFqW4f1XNntG4Rdq0VvGFOHh4FtIuJtEfF2ajP4vto5Ijavvnn4NLXrv5KkJmnYzDQzl1XluSVwOjAXeJDaacsTqd0ItEGP1zxezQAviYj1q8WnZOa9EXE+tYL+M/Afq9n1nIh4gdoNTNdTXT/MzMURcRHwh2rcBZl5a3UD0ps5ldrNUY9Xfw7rZcwRwA8jIqnjBqSeMvOhiLia2mnrB4HFfd0Gtc/p+9RuTLqe104NS5KaIBp502dEjAfmACdR+08eYDIwOjPrud6pNaju5n31buB6rD9qXI767FkNTCVJzdPZpGumEbEoM6f0tq6hP2eamcuAT1K7O3YxtTtrZwJLV/c6SZLaScPfNCAzlwOfb/R+3qoy83pem/VLkgaA780rSVIhy1SSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKmQZSpJUiHLVJKkQpapJEmFLFNJkgpZppIkFbJMJUkqZJlKklTIMpUkqZBlKklSIctUkqRClqkkSYUGDXQANd+279mYhbP2GugYkrTOcGYqSVIhy1SSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKmQZSpJUiHLVJKkQpapJEmFLFNJkgrVVaYRsWFEnBoR51fPx0XE3o2NJklSe6h3Znoh8ALwwer5I8DpDUkkSVKbqbdMt8jMbwAvAWTmSiAalkqSpDZSb5m+GBEbAAkQEVtQm6lKkvSWV+8vB/8qcB2wWUTMAXYBpjcqlCRJ7aSuMs3M30bEYmBnaqd3v5iZTzQ0mSRJbWK1ZRoRk3sseqz6c/OI2DwzFzcmliRJ7WNNM9Nvr2ZdAh/uxyySJLWl1ZZpZk5rVhBJktrVmk7z7r+69Zn5s/6NI0lS+1nTad5PVH9uCnwI+Lfq+TTgJsAylSS95a3pNO8RABHxG2DrzHysej4KuKjh6SRJagP1vmnDZl1FWvkLsHkD8kiS1HbqfdOG30XEr4FLqucHAdc3JpIkSe2l3jdtOL66GWlqtWh2Zl7VuFiSJLWPememXXfuesORJEk91Pv7TPePiPsi4umI+FtEPBMRf2t0OEmS2kG9M9NvAJ/IzGWNDCNJUjuq927ev1ikkiT1rt6Z6cKIuAy4mm6/x9R3QJIkqf4yHQ6sBHbvtizxhiRJkur+0ZgjGh1EkqR2VVeZRsQQ4HPANsCQruWZeWSDckmS1DbqvQHpJ8C7gX8E/h0YAzzTqFCSJLWTesv0fZl5KvBsZv4I2Av4QONiSZLUPuot05eqP5+KiAnAxtR+LZskSW959d7NOzsi3g6cAlwDDAVObVgqSZLaSL1l+hPgAKAD+FG17F2NCCRJUrupt0x/DjwNLKLbmzZIkqT6y3RMZu7R0CSSJLWpem9Auikitm1oEkmS2tRqZ6YRcTu1tw0cBBwREQ9SO80bQGbmxMZHlCSpta3pNO/eTUkhSVIbW22ZZubDzQoiSVK7qveaqSRJehOWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKlQve/Nq3XI7Y88TcfJ1w50DEl6g85Zew10hLXizFSSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKmQZSpJUiHLVJKkQpapJEmFLFNJkgpZppIkFbJMJUkqZJlKklTIMpUkqZBlKklSIctUkqRClqkkSYUsU0mSClmmkiQVskwlSSpkmUqSVMgylSSpUFuVaUS8KyLOjoilEbE4Ii6IiM26rV/RY/z0iPhu9fjzEfFP1eOLIuLA6vG8iJjST/kGR8SsiLivyndzRHy8WtcZEZtUj2+qY1tfiogN+yOXJKmx2qZMI2IL4DrgRmBKZk4GLgGuqtatVmZ+PzN/3A851lvN6q8Bo4AJVb59gWG9ZPlQHbv6EmCZSlIbGDTQAfrge8BnM3Np14LM/F1EHA58m1pxvamIOA1YkZnfWs2Y7wE7AhsAV2TmV6vlncBlwMeAKyPigKosiYhx1bpdgaOBsZn5QpXvL8BPe9nPiswcGhG7AacBTwATgEXA4cAXgNHA3Ih4IjOnRcQhwP8EArg2M0/q2hZwNrA38BywT7VfSWoJf7745LrH7rbgm3WPnTdv3lqkaYy2mJlGxPuBxzNzaUTsXZ1CvSIirszMu4FV1SnUDSJiSdcH8M993NVXMnMKMBH4bxExsdu6JzNzcmb+H+DpiJhULT8CuBB4H/DHzPxbH/e5PbVZ6NbAe4FdMvM7wKPAtKpIRwNnAB8GJgE7RkTXNw8bAQsyczvg99QK/Q0iYkZELIyIha+sfLqPESVJq9MuM9PtgAXVKdavUiuVjYE7qvX3AWOB5zKzq+SIiOlAX66HfjoiZlA7LqOoFVzXTPiybuMuAI6IiC8DBwE7Ae/p4+fU5Q+ZubzKuwToAOb3GLMjMC8zH6/GzQH+AbgaeBH412rcImqz5zfIzNnAbID1R43LtcwqSX327kNn1T123qy9GpikcdpiZlp5BdgEeCAzn8rMh4G7qnWbAv9ZsvGIGAucCHwkMycC1wJDug15ttvjK4GPUzu1uigznwTuBzaPiOF93PUL3R6/Qt+/wXkpM7vKcW1eL0kq1C5legfwAWrXFreIiI0jYnNgfERsC2xalWuJ4dQK8+mIeBe1suxVZj4P/JraddwLq2UrgX8Bzo6ItwFExDsj4lNrmecZXrt56Q/UTjtvUs3ODwH+fS23K0nqZ21Rppm5DNgc2BI4HZgLnAlcQ202eWQ/7OM24FbgbuBiancNr84cYBXwm27LTgEeB+6KiDuonX7t6zXULrOB6yJibmY+BpxM7fO+jdps+OdruV1JUj+L184QtraIGE+twE4Crq8WTwZGZ+YvBiDPicDGmXlqs/ddav1R43LUZ88a6BiS9AadLXzNNCIWVTepvkHbXF/LzGUR8Ulqs79vAOtRO/35tWZniYirgC2o3QglSXqLa5syBajuev18C+TYb6AzSJJaR1tcM5UkqZVZppIkFbJMJUkqZJlKklTIMpUkqZBlKklSIctUkqRClqkkSYUsU0mSClmmkiQVskwlSSpkmUqSVMgylSSpkGUqSVIhy1SSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUaNBAB1DzbfuejVk4a6+BjiFJ6wxnppIkFbJMJUkqZJlKklTIMpUkqZBlKklSIctUkqRClqkkSYUsU0mSClmmkiQVskwlSSpkmUqSVMgylSSpkGUqSVIhy1SSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKmQZSpJUiHLVJKkQpapJEmFLFNJkgpZppIkFbJMJUkqFJk50BnUZBHxDHDPQOdYjU2AJwY6xGqYr4z5yrRyvlbOBuX5/j4z39nbikEFG1X7uiczpwx0iDcTEQvNt/bMV8Z8a6+Vs0Fj83maV5KkQpapJEmFLNO3ptkDHWANzFfGfGXMt/ZaORs0MJ83IEmSVMiZqSRJhSxTSZIKWabrsIjYIyLuiYj7I+LkXtavHxGXVetviYiOFsv3DxGxOCJejogDm5mtznxfjoi7ImJpRPwuIv6+xfJ9PiJuj4glETE/IrZupXzdxh0QERkRTfuRijqO3fSIeLw6dksi4qhmZasnXzXm09Xfvzsj4uJWyhcR/7fbsbs3Ip5qsXybR8TciLi1+ve7Z/FOM9OPdfADWA94AHgv8DbgNmDrHmOOBb5fPT4YuKzF8nUAE4EfAwe24PGbBmxYPZ7ZgsdveLfHnwSua6V81bhhwO+BBcCUVskGTAe+28y/c33MNw64FXh79XzTVsrXY/wXgB+2Uj5qNyLNrB5vDXSW7teZ6bprJ+D+zHwwM18ELgX26TFmH+BH1eMrgI9ERLRKvszszMylwKomZeprvrmZubJ6ugAY02L5/tbt6UZAM+82rOfvH8DXgDOA51sw20CpJ9/RwLmZ+V8AmfmfLZavu0OAS5qSrKaefAkMrx5vDDxaulPLdN31HuBP3Z4vr5b1OiYzXwaeBkY2JV19+QZSX/N9DvhVQxO9Xl35IuK4iHgA+AZwQpOyQR35ImIysFlmXtvEXFD/1/aA6hTgFRGxWXOiAfXlez/w/oi4MSIWRMQeTUvXh38b1aWPscC/NSFXl3rynQYcHhHLgV9Smz0XsUylQhFxODAF+OZAZ+kpM8/NzC2Ak4BTBjpPl4j4O+BM4L8PdJY38QugIzMnAr/ltTM4rWIQtVO9u1Gb+Z0fESMGNFHvDgauyMxXBjpID4cAF2XmGGBP4CfV38m1Zpmuux4Bun83PaZa1uuYiBhE7XTHk01JV1++gVRXvoj4KPAV4JOZ+UKTskHfj9+lwL4NTfR6a8o3DJgAzIuITmBn4Jom3YS0xmOXmU92+3peAOzQhFxd6vnaLgeuycyXMvMh4F5q5doq+bocTHNP8UJ9+T4H/BQgM28GhlB7E/y116yLwn4094Pad64PUjvF0nURfpseY47j9Tcg/bSV8nUbexHNvwGpnuO3PbUbHca16Nd3XLfHnwAWtlK+HuPn0bwbkOo5dqO6Pd4PWNBKxw7YA/hR9XgTaqc1R7ZKvmrcVkAn1ZsDtdjx+xUwvXo8nto106KcTfsE/Wj+B7XTF/dW/+F/pVr2z9RmUVD7buxy4H7gD8B7WyzfjtS+A3+W2oz5zhbLdz3wF2BJ9XFNi+U7G7izyjZ3dWU2EPl6jG1amdZ57L5eHbvbqmO3VSsdOyConSa/C7gdOLiV8lXPTwNmNTNXH47f1sCN1dd3CbB76T59O0FJkgp5zVSSpEKWqSRJhSxTSZIKWaaSJBWyTCVJKmSZSpJUyDKVJKnQ/wfJzQsdNO39mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_pd.plot(x='handle', y='prediction', xerr='err', kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review='Moderator: Hillary paid $225,000 by a Brazilian bank for a speech that called for “open borders.” That’s a quote! #Debate #BigLeagueTruth'),\n",
       " Row(review='Hillary is too weak to lead on border security-no solutions, no ideas, no credibility.She supported NAFTA, worst deal in US history. #Debate'),\n",
       " Row(review='UNBELIEVABLE!\\nClinton campaign contractor caught in voter-fraud video is a felon who visited White House 342 times: https://t.co/qQdsMHAtkT'),\n",
       " Row(review='Obamacare premiums increasing 33% in Pennsylvania - a complete disaster. It must be repealed and replaced!… https://t.co/aDZEfcI7SM'),\n",
       " Row(review=\"'Dem Operative Who Oversaw Trump Rally Agitators Visited White House 342 Times' #DrainTheSwamp \\nhttps://t.co/MO4SJaQMzo\")]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#But let’s examine some “negative” tweets by Trump\n",
    "best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    where(fn.col('handle') == '@realDonaldTrump').\\\n",
    "    where(fn.col('prediction') == 0).\\\n",
    "    select('review').\\\n",
    "    take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review=\"We're going to make college debt-free for everyone in America. See how much you could save with Hillary's plan at… https://t.co/Fhzkubhpj7\"),\n",
       " Row(review=\"Don't boo. Vote! https://t.co/tTgeqy51PU https://t.co/9un3FUVxoG\"),\n",
       " Row(review='This Republican dad is struggling with the idea of his daughter growing up in a country led by Donald Trump. https://t.co/Tn3rQqJJKp'),\n",
       " Row(review='Hillary teamed up with @BernieSanders on a plan to make college debt-free for all Americans. https://t.co/sdWVzdxIrG'),\n",
       " Row(review=\"There are hundreds of thousands more @AmeriCorps applications than spots. Horrible! Let's expand it from 75,000 annual members to 250,000.\")]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And Clinton\n",
    "best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    where(fn.col('handle') == '@HillaryClinton').\\\n",
    "    where(fn.col('prediction') == 0).\\\n",
    "    select('review').\\\n",
    "    take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
